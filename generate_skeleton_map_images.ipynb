{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "import argparse\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3'\n",
    "import os.path as osp\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.models as models\n",
    "from transform_cnn import VA\n",
    "from data_cnn import NTUDataLoaders, AverageMeter,  make_dir, get_cases, get_num_classes\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.ArgumentParser(description='View adaptive')\n",
    "args.add_argument('--model', type=str, default='VA',\n",
    "                  help='the neural network to use')\n",
    "args.add_argument('--dataset', type=str, default='NTU',\n",
    "                  help='select dataset to evlulate')\n",
    "args.add_argument('-b', '--batch_size', type=int, default=1,\n",
    "                  help='mini-batch size (default: 256)')\n",
    "args.add_argument('--num_classes', type=int, default=60,\n",
    "                  help='the number of classes')\n",
    "args.add_argument('--case', type=int, default=1,\n",
    "                  help='select which case')\n",
    "args.add_argument('--aug', type=int, default=1,\n",
    "                  help='data augmentation')\n",
    "args.add_argument('--workers', type=int, default=8,\n",
    "                  help='number of data loading workers')\n",
    "args = args.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = get_num_classes(args.dataset)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35763 samples, validate on 20815 samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = get_num_classes(args.dataset)\n",
    "\n",
    "# Data loading\n",
    "ntu_loaders = NTUDataLoaders(args.dataset, args.case, args.aug)\n",
    "train_loader = ntu_loaders.get_train_loader(args.batch_size, args.workers)\n",
    "val_loader = ntu_loaders.get_val_loader(args.batch_size, args.workers)\n",
    "train_size = ntu_loaders.get_train_size()\n",
    "val_size = ntu_loaders.get_val_size()\n",
    "print('Train size %d samples, validattion size %d samples' %\n",
    "      (train_size, val_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "#action=[*range(0,60,1)]\n",
    "action=[40,41,42,43,44,45,46,47,48]\n",
    "\n",
    "for i, (inputs, maxmin, target) in enumerate(train_loader):\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    target = target.to(device) \n",
    "\n",
    "    act= int(target)\n",
    "    if act in action:\n",
    "        filename_format = \"image-{0}-{1}.png\"\n",
    "        #print(act)\n",
    "        \n",
    "        #set the directory path where you want to keep the generated training images\n",
    "        base_dir = \"/home/fatema/Documents/action_rec/project/img_ske_all/train\"\n",
    "\n",
    "\n",
    "        image_path_dir = os.path.join(base_dir, str(act))\n",
    "        if not os.path.exists(image_path_dir):\n",
    "            os.mkdir(image_path_dir)\n",
    "        file_count = str(len(os.listdir(image_path_dir))+1)\n",
    "        image_save_path = os.path.join(image_path_dir, filename_format.format(str(act), file_count))\n",
    "\n",
    "        #print(inputs.shape)\n",
    "        #print(type(inputs)) \n",
    "        #print(labels)\n",
    "        data=torch.squeeze(inputs, 0)\n",
    "        #print(data.shape)\n",
    "        data=data[0]\n",
    "        #print(data.shape)\n",
    "        data=data.cpu().numpy()    \n",
    "\n",
    "        #print(data.shape)\n",
    "\n",
    "        matplotlib.image.imsave(image_save_path, data)\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "#action=[*range(0,60,1)]\n",
    "action=[40,41,42,43,44,45,46,47,48]\n",
    "for i, (inputs, maxmin, target) in enumerate(val_loader):\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    target = target.to(device) \n",
    "\n",
    "    act= int(target)\n",
    "    if act in action:\n",
    "        filename_format = \"image-{0}-{1}.png\"\n",
    "        #print(act)\n",
    "        #set the directory path where you want to keep the generated validation images\n",
    "        base_dir = \"/home/fatema/Documents/action_rec/project/img_ske_all/val\"\n",
    "\n",
    "\n",
    "        image_path_dir = os.path.join(base_dir, str(act))\n",
    "        if not os.path.exists(image_path_dir):\n",
    "            os.mkdir(image_path_dir)\n",
    "        file_count = str(len(os.listdir(image_path_dir))+1)\n",
    "        image_save_path = os.path.join(image_path_dir, filename_format.format(str(act), file_count))\n",
    "\n",
    "        #print(inputs.shape)\n",
    "        #print(type(inputs)) \n",
    "        #print(labels)\n",
    "        data=torch.squeeze(inputs, 0)\n",
    "        #print(data.shape)\n",
    "        data=data[0]\n",
    "        #print(data.shape)\n",
    "        data=data.cpu().numpy()    \n",
    "\n",
    "        #print(data.shape)\n",
    "\n",
    "        matplotlib.image.imsave(image_save_path, data)\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
